{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZ8IOfmx4FUTagoSqt0OK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dchirosca/bot-detection-econophysics/blob/main/bot_detection_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akmxWKZLH0Ju"
      },
      "outputs": [],
      "source": [
        "library(readr)\n",
        "library(dplyr)\n",
        "library(ggplot2)\n",
        "library(corrplot)\n",
        "library(caret)\n",
        "library(class)\n",
        "library(xgboost)\n",
        "library(Matrix)\n",
        "library(iml)\n",
        "options(scipen = 99)\n",
        "\n",
        "# Data pre-processing -----------------------------------------------------\n",
        "\n",
        "# Keeping the columns relevant for analysis\n",
        "col_to_keep<-c(\"created_at\", \"description\", \"favourites_count\", \"followers_count\", \"friends_count\", \"geo_enabled\", \"id\", \"screen_name\", \"statuses_count\",\n",
        "               \"average_tweets_per_day\", \"account_type\")\n",
        "dataset<-subset(dataset, select = col_to_keep)\n",
        "dataset$account_type<-as.factor(dataset$account_type)\n",
        "\n",
        "dataset$geo_enabled<-ifelse(dataset$geo_enabled == \"TRUE\", 1, 0)\n",
        "\n",
        "description_char_l<-ifelse(is.na(dataset$description) == TRUE, 0, nchar(dataset$description))\n",
        "description_no_words<-c()\n",
        "for(i in 1:dim(dataset)[1]){\n",
        "  if(is.na(dataset$description[i]) == TRUE){\n",
        "    description_no_words[i]<-0\n",
        "  } else{\n",
        "    description_no_words[i]<-length(strsplit(dataset$description[i], \" \")[[1]])\n",
        "  }\n",
        "}\n",
        "dataset<-cbind(dataset, description_char_l, description_no_words)\n",
        "\n",
        "dt<-dataset\n",
        "# Removing rows with 0 for numeric variables\n",
        "dt<-dt %>% filter(followers_count>0)\n",
        "dt<-dt %>% filter(favourites_count>0)\n",
        "dt<-dt %>% filter(friends_count>0)\n",
        "dt<-dt %>% filter(statuses_count>0)\n",
        "dt<-dt %>% filter(average_tweets_per_day>0)\n",
        "dt<-dt %>% filter(description_char_l>0)\n",
        "dt<-dt %>% filter(description_no_words>0)\n",
        "dt$average_tweets_per_day<-ceiling(dt$average_tweets_per_day)\n",
        "\n",
        "dt_bot<-dt %>% filter(account_type == \"bot\")\n",
        "dt_human<-dt %>% filter(account_type == \"human\")\n",
        "\n",
        "# Calculating Benford's law -----------------------------------------------\n",
        "\n",
        "benfords_distribution<-log10(1 + 1/(1:9))\n",
        "extract_leading_digit<-function(x) {\n",
        "  as.numeric(substr(as.character(x), 1, 1))\n",
        "}\n",
        "\n",
        "benfords_law<-function(variable){\n",
        "  leading_digits<-sapply(variable, extract_leading_digit)\n",
        "  digit_distribution<-table(leading_digits)/length(leading_digits)\n",
        "  observed<-as.numeric(digit_distribution*length(leading_digits))\n",
        "  names(observed)<-names(digit_distribution)\n",
        "  if(length(names(observed)) < 9){\n",
        "    vector_of_z<-rep(0, times = 9-length(names(observed)))\n",
        "    observed<-c(observed, vector_of_z)\n",
        "    names(observed)<-c(1:9)\n",
        "  }\n",
        "  chisq_test<-chisq.test(observed, p = benfords_distribution)\n",
        "  if(chisq_test$p.value < 0.05){\n",
        "    conclusion<-\"The distribution significantly differs from Benford's law distribution\"\n",
        "  } else{\n",
        "    conclusion<-\"The distribution DOES NOT significantly differ from Benford's law distribution\"\n",
        "  }\n",
        "  return(conclusion)\n",
        "}\n",
        "\n",
        "\n",
        "# Benford's law study for the entire dataset -----------------------------------------------------\n",
        "\n",
        "benfords_law(dt$followers_count)\n",
        "benfords_law(dt$favourites_count)\n",
        "benfords_law(dt$friends_count)\n",
        "benfords_law(dt$statuses_count)\n",
        "benfords_law(dt$average_tweets_per_day)\n",
        "benfords_law(dt$description_char_l)\n",
        "benfords_law(dt$description_no_words)\n",
        "\n",
        "# Benford's law study for the human dataset -----------------------------------------------------\n",
        "\n",
        "benfords_law(dt_human$followers_count)\n",
        "\n",
        "benfords_law(dt_human$favourites_count) # The distribution DOES NOT significantly differ from Benford's law distribution\n",
        "leading_digits<-sapply(dt_human$favourites_count, extract_leading_digit)\n",
        "digit_distribution<-table(leading_digits)/length(leading_digits)\n",
        "barplot(digit_distribution, main = \"Distributia primei cifre pentru variabila de tweeturi favorite\",\n",
        "        names.arg = 1:9,\n",
        "        ylim = c(0, max(digit_distribution, benfords_distribution)),\n",
        "        col = \"#619cff\")\n",
        "points(1:9, benfords_distribution, col = \"black\", pch = 21, cex = 1.8)\n",
        "\n",
        "benfords_law(dt_human$friends_count)\n",
        "\n",
        "benfords_law(dt_human$statuses_count) # The distribution DOES NOT significantly differ from Benford's law distribution\n",
        "leading_digits<-sapply(dt_human$statuses_count, extract_leading_digit)\n",
        "digit_distribution<-table(leading_digits)/length(leading_digits)\n",
        "barplot(digit_distribution, main = \"Distributia primei cifre pentru variabila de total statusuri\",\n",
        "        names.arg = 1:9,\n",
        "        ylim = c(0, max(digit_distribution, benfords_distribution)),\n",
        "        col = \"#619cff\")\n",
        "points(1:9, benfords_distribution, col = \"black\", pch = 21, cex = 1.8)\n",
        "\n",
        "benfords_law(dt_human$average_tweets_per_day)\n",
        "benfords_law(dt_human$description_char_l)\n",
        "benfords_law(dt_human$description_no_words)\n",
        "\n",
        "# Benford's law study for the bot dataset -----------------------------------------------------\n",
        "\n",
        "benfords_law(dt_bot$followers_count)\n",
        "benfords_law(dt_bot$favourites_count)\n",
        "benfords_law(dt_bot$friends_count)\n",
        "benfords_law(dt_bot$statuses_count)\n",
        "benfords_law(dt_bot$average_tweets_per_day)\n",
        "benfords_law(dt_bot$description_char_l)\n",
        "benfords_law(dt_bot$description_no_words)\n",
        "\n",
        "\n",
        "# Exploratory data analysis -----------------------------------------------\n",
        "\n",
        "account_count_plot<-ggplot(dataset)+\n",
        "  geom_bar(aes(x=account_type, fill=account_type))+\n",
        "  theme(legend.title=element_text(size=12,face=\"bold\"), plot.title = element_text(size=16,face=\"bold\",hjust = 0.5))+\n",
        "  scale_color_manual(values=c(\"#f8766d\", \"#00ba38\", \"#619cff\"))+\n",
        "  labs(title=\"Tipul de conturi de Twitter din setul de date\",x=\"Cluster\", y = \"Venit anual\")\n",
        "account_count_plot\n",
        "\n",
        "favourites_plot<-ggplot(dataset, aes(x=account_type,y=favourites_count,fill=account_type))+\n",
        "  geom_boxplot(outlier.colour=\"black\", outlier.shape=16,outlier.size=2, notch=T)+\n",
        "  theme(legend.title=element_text(size=12,face=\"bold\"), plot.title = element_text(size=16,face=\"bold\",hjust = 0.5))+\n",
        "  scale_color_manual(values=c(\"#f8766d\", \"#00ba38\", \"#619cff\"))+\n",
        "  labs(title=\"Numarul de favourites in functie de tipul de cont\",x=\"Tip cont\", y = \"Numar de favourites\")\n",
        "favourites_plot\n",
        "\n",
        "statuses_plot<-ggplot(dataset, aes(x=account_type,y=statuses_count,fill=account_type))+\n",
        "  geom_boxplot(outlier.colour=\"black\", outlier.shape=16,outlier.size=2, notch=T)+\n",
        "  theme(legend.title=element_text(size=12,face=\"bold\"), plot.title = element_text(size=16,face=\"bold\",hjust = 0.5))+\n",
        "  scale_color_manual(values=c(\"#f8766d\", \"#00ba38\", \"#619cff\"))+\n",
        "  labs(title=\"Numarul de statusuri in functie de tipul de cont\",x=\"Tip cont\", y = \"Numar de statusuri\")\n",
        "statuses_plot\n",
        "\n",
        "# Correlation matrix for numeric variables\n",
        "cor_matrix<-cor(dataset%>%select_if(is.numeric))\n",
        "# Correlation plot\n",
        "corrplot(cor_matrix, method = \"circle\")\n",
        "\n",
        "cor_matrix_human<-cor(dt_human%>%select_if(is.numeric))\n",
        "corrplot(cor_matrix_human, method = \"circle\")\n",
        "\n",
        "cor_matrix_bot<-cor(dt_bot%>%select_if(is.numeric))\n",
        "corrplot(cor_matrix_bot, method = \"circle\")\n",
        "\n",
        "# Data mining -------------------------------------------------------------\n",
        "\n",
        "# K-Nearest Neighbors -----------------------------------------------------\n",
        "\n",
        "# Selecting relevant features and the target variable\n",
        "features<-dataset[, -which(names(dataset) %in% c(\"account_type\", \"created_at\", \"description\", \"id\", \"screen_name\", \"description_char_l\"))]\n",
        "target<-dataset$account_type\n",
        "\n",
        "# Splitting the dataset\n",
        "set.seed(121)  # For reproducibility\n",
        "splitIndex<-createDataPartition(target, p = 0.75, list = FALSE) # splitting the dataset in 80-20 training and test\n",
        "train_data<-dataset[splitIndex,]\n",
        "test_data<-dataset[-splitIndex,]\n",
        "\n",
        "# Selecting relevant features and the target variable\n",
        "features<-dataset[, -which(names(dataset) %in% c(\"account_type\", \"created_at\", \"description\", \"id\", \"screen_name\", \"description_char_l\"))]\n",
        "target<-dataset$account_type\n",
        "\n",
        "# Splitting the dataset\n",
        "set.seed(121)  # For reproducibility\n",
        "splitIndex<-createDataPartition(target, p = 0.75, list = FALSE) # splitting the dataset in 80-20 training and test\n",
        "train_data<-dataset[splitIndex,]\n",
        "test_data<-dataset[-splitIndex,]\n",
        "\n",
        "# Normalizing the data\n",
        "preProcValues<-preProcess(train_data, method = c(\"center\", \"scale\"))\n",
        "train_data<-predict(preProcValues, train_data)\n",
        "test_data<-predict(preProcValues, test_data)\n",
        "\n",
        "# Extracting features and target variable from training and test sets\n",
        "train_features <- train_data[, -which(names(train_data) %in% c(\"account_type\", \"created_at\", \"description\", \"id\", \"screen_name\", \"description_char_l\"))]\n",
        "train_target <- train_data$account_type\n",
        "test_features <- test_data[, -which(names(test_data) %in% c(\"account_type\", \"created_at\", \"description\", \"id\", \"screen_name\", \"description_char_l\"))]\n",
        "test_target <- test_data$account_type\n",
        "\n",
        "# Trying the KNN algorithm for different k values\n",
        "accuracy<-c()\n",
        "for (k in 1:20) {\n",
        "  knn_model <- knn(train = train_features, test = test_features, cl = train_target, k = k)\n",
        "  confusionMatrix<-table(test_target, knn_model)\n",
        "  accuracy[k]<-sum(diag(confusionMatrix)) / sum(confusionMatrix)\n",
        "}\n",
        "\n",
        "accuracy_res<-data.frame(k = c(1:20), accuracy)\n",
        "accuracy_res[which.max(accuracy_res$accuracy),] # the maximum accuracy is recorded for k = 10 neighbors\n",
        "\n",
        "knn_model_k10<-knn(train = train_features, test = test_features, cl = train_target, k = 10)\n",
        "confusionMatrix_k10<-table(test_target, knn_model)\n",
        "confusionMatrix_k10\n",
        "accuracy_k10<-sum(diag(confusionMatrix)) / sum(confusionMatrix)\n",
        "accuracy_k10 # 0.8186772\n",
        "\n",
        "barplot(accuracy, main = \"Acuratetea algoritmilor KNN pentru diferite valori ale lui k\",\n",
        "        names.arg = 1:20,\n",
        "        col = \"#619cff\")\n",
        "\n",
        "# XGBoost -----------------------------------------------------------------\n",
        "\n",
        "features<-dataset[, -which(names(dataset) %in% c(\"account_type\", \"created_at\", \"description\", \"id\", \"screen_name\", \"description_char_l\"))]\n",
        "target<-dataset$account_type\n",
        "\n",
        "# Splitting the dataset\n",
        "df<-dataset[, -which(names(dataset) %in% c(\"created_at\", \"description\", \"id\", \"screen_name\", \"description_char_l\"))]\n",
        "df$account_type<-ifelse(df$account_type == \"bot\", 1, 0)\n",
        "set.seed(121)  # For reproducibility\n",
        "splitIndex<-createDataPartition(target, p = 0.75, list = FALSE) # splitting the dataset in 80-20 training and test\n",
        "train_data<-df[splitIndex,]\n",
        "test_data<-df[-splitIndex,]\n",
        "\n",
        "# Separate features and labels\n",
        "train_label<-train_data$account_type\n",
        "train_data<-train_data[, -which(names(train_data) == \"account_type\")]\n",
        "\n",
        "test_label<-test_data$account_type\n",
        "test_data<-test_data[, -which(names(test_data) == \"account_type\")]\n",
        "\n",
        "dtrain<-xgb.DMatrix(data = as.matrix(train_data), label = train_label)\n",
        "dtest<-xgb.DMatrix(data = as.matrix(test_data), label = test_label)\n",
        "\n",
        "params<-list(\n",
        "  objective = \"binary:logistic\",\n",
        "  eta = 0.1,\n",
        "  max_depth = 9,\n",
        "  nthread = 2\n",
        ")\n",
        "\n",
        "set.seed(121)  # for reproducibility\n",
        "xgb_model<-xgb.train(params, dtrain, nrounds = 10000)\n",
        "\n",
        "# Predictions\n",
        "preds<-predict(xgb_model, dtest)\n",
        "preds<-ifelse(preds > 0.5, 1, 0)\n",
        "\n",
        "# Confusion Matrix to evaluate performance\n",
        "confusionMatrix(factor(preds), factor(test_label)) # 0.8704\n",
        "\n",
        "importance_matrix <- xgb.importance(feature_names = colnames(train_data), model = xgb_model)\n",
        "xgb.plot.importance(importance_matrix)"
      ]
    }
  ]
}